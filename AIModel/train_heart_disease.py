
"""
TRAIN HEART DISEASE PREDICTION MODEL (SIMPLE)
Dataset: heart.csv (Kaggle)
"""


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib
import os

print("==============================")
print("TRAIN HEART DISEASE MODEL")
print("==============================")

# ÄÆ°á»ng dáº«n file csv
csv_path = os.path.join(os.path.dirname(__file__), "data", "heart.csv")
print(f"[DEBUG] ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i file: {csv_path}")
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file: {csv_path}")

# Äá»c dá»¯ liá»‡u
print("Äang Ä‘á»c dá»¯ liá»‡u...")
df = pd.read_csv(csv_path)
print(f"ÄÃ£ load dá»¯ liá»‡u: {df.shape[0]} dÃ²ng, {df.shape[1]} cá»™t")

# XÃ¡c Ä‘á»‹nh cá»™t target duy nháº¥t
possible_targets = ["target", "HeartDisease", "output", "condition", "num"]
target_col = None
for col in possible_targets:
    if col in df.columns:
        target_col = col
        break
if not target_col:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t target trong dá»¯ liá»‡u!")
    print(f"CÃ¡c cá»™t cÃ³: {list(df.columns)}")
    exit(1)
print(f"âœ… Cá»™t target: {target_col}")

# Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
X = df.drop(target_col, axis=1)
y = df[target_col]

# Encode categorical columns náº¿u cÃ³
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = X[col].astype('category').cat.codes

# Chia train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

# ÄÃ¡nh giÃ¡
y_pred = model.predict(X_test_scaled)
acc = accuracy_score(y_test, y_pred)
print(f"Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {acc*100:.2f}%")
print(classification_report(y_test, y_pred))

# LÆ°u model, scaler, features
joblib.dump(model, "heart_model.pkl")
joblib.dump(scaler, "heart_scaler.pkl")
joblib.dump(list(X.columns), "heart_features.pkl")
print("ÄÃ£ lÆ°u model, scaler, features!")

# 2. XÃ¡c Ä‘á»‹nh cá»™t target
possible_targets = ["target", "HeartDisease", "output", "condition", "num"]
target_col = None
for col in possible_targets:
    if col in df.columns:
        target_col = col
        break
if not target_col:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t target trong dá»¯ liá»‡u!")
    print(f"CÃ¡c cá»™t cÃ³: {list(df.columns)}")
    exit(1)
print(f"âœ… Cá»™t target: {target_col}")

# 3. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
X = df.drop(target_col, axis=1)
y = df[target_col]

# Encode categorical columns náº¿u cÃ³
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = X[col].astype('category').cat.codes

# 4. Chia train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 5. Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6. Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

# 7. ÄÃ¡nh giÃ¡
y_pred = model.predict(X_test_scaled)
acc = accuracy_score(y_test, y_pred)
print(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test: {acc*100:.2f}%")
print(classification_report(y_test, y_pred))

# 8. LÆ°u model, scaler, features

# LÆ°u model vá»›i tÃªn Ä‘á»“ng bá»™
joblib.dump(model, "heart_model.pkl")
joblib.dump(scaler, "heart_scaler.pkl")
joblib.dump(list(X.columns), "heart_features.pkl")
print("âœ… ÄÃ£ lÆ°u model, scaler, features!")

print("\nHoÃ n thÃ nh train mÃ´ hÃ¬nh bá»‡nh tim!")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')


target_columns = ['HeartDisease', 'target', 'output', 'condition', 'num']
target_col = None
for col in target_columns:
    if col in df.columns:
        target_col = col
        break

if target_col is None:
    print("âŒ Cannot find target column!")
    print(f"   Available columns: {list(df.columns)}")
    exit()

print(f"âœ… Target column: {target_col}")

# TÃ¡ch X vÃ  y
X = df.drop(target_col, axis=1)
y = df[target_col]

# Encode categorical features náº¿u cÃ³
le = LabelEncoder()
for col in X.columns:
    if X[col].dtype == 'object':
        print(f"   Encoding column: {col}")
        X[col] = le.fit_transform(X[col])

print(f"\nâœ… Features: {list(X.columns)}")
print(f"âœ… Target distribution:")
print(y.value_counts())
print(f"   Class 0: {(y == 0).sum()} ({(y == 0).sum()/len(y)*100:.1f}%)")
print(f"   Class 1: {(y == 1).sum()} ({(y == 1).sum()/len(y)*100:.1f}%)")

# ============================================================
# BÆ¯á»šC 4: SPLIT DATA
# ============================================================
print("\nâœ‚ï¸  BÆ¯á»šC 4: Splitting data...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"âœ… Train set: {X_train.shape[0]} samples")
print(f"âœ… Test set: {X_test.shape[0]} samples")

# ============================================================
# BÆ¯á»šC 5: FEATURE SCALING
# ============================================================
print("\nğŸ“ BÆ¯á»šC 5: Feature Scaling...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
print("âœ… Scaling completed!")

# ============================================================
# BÆ¯á»šC 6: TRAIN MULTIPLE MODELS
# ============================================================
print("\nğŸ¤– BÆ¯á»šC 6: Training Multiple Models...")
print("-"*70)

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(kernel='rbf', probability=True, random_state=42)
}

best_model = None
best_model_name = None
best_accuracy = 0
results = {}

for name, model in models.items():
    print(f"\nğŸ”¹ Training {name}...")
    
    # Train model
    model.fit(X_train_scaled, y_train)
    
    # Predict
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
    
    # Evaluate
    accuracy = accuracy_score(y_test, y_pred)
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    
    print(f"   âœ… Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   âœ… Cross-val score: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
    
    if y_pred_proba is not None:
        roc_auc = roc_auc_score(y_test, y_pred_proba)
        print(f"   âœ… ROC-AUC: {roc_auc:.4f}")
    
    print(f"\n   ğŸ“Š Classification Report:")
    print("   " + "-"*65)
    report = classification_report(y_test, y_pred, target_names=['No Disease', 'Disease'])
    for line in report.split('\n'):
        print(f"   {line}")
    
    # Save results
    results[name] = {
        'accuracy': accuracy,
        'cv_score': cv_scores.mean(),
        'model': model
    }
    
    # Track best model
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = model
        best_model_name = name

# ============================================================
# BÆ¯á»šC 7: SAVE BEST MODEL
# ============================================================
print("\n"+"="*70)
print("ğŸ† BEST MODEL RESULTS")
print("="*70)
print(f"âœ… Best Model: {best_model_name}")
print(f"âœ… Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")

print("\nğŸ’¾ Saving models...")
joblib.dump(best_model, 'heart_disease_model.pkl')
joblib.dump(scaler, 'heart_disease_scaler.pkl')
print("âœ… Saved: heart_disease_model.pkl")
print("âœ… Saved: heart_disease_scaler.pkl")

# LÆ°u feature names
feature_names = list(X.columns)
joblib.dump(feature_names, 'heart_disease_features.pkl')
print(f"âœ… Saved: heart_disease_features.pkl")
print(f"   Features: {feature_names}")

# ============================================================
# BÆ¯á»šC 8: VISUALIZATION
# ============================================================
print("\nğŸ“Š BÆ¯á»šC 8: Creating visualizations...")

# 1. Model Comparison
plt.figure(figsize=(10, 6))
model_names = list(results.keys())
accuracies = [results[m]['accuracy'] for m in model_names]
plt.bar(model_names, accuracies, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])
plt.ylim(0.5, 1.0)
plt.ylabel('Accuracy')
plt.title('Model Comparison - Accuracy')
plt.xticks(rotation=45, ha='right')
for i, v in enumerate(accuracies):
    plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')
plt.tight_layout()
plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
print("âœ… Saved: model_comparison.png")

# 2. Confusion Matrix
y_pred_best = best_model.predict(X_test_scaled)
cm = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['No Disease', 'Disease'],
            yticklabels=['No Disease', 'Disease'])
plt.title(f'Confusion Matrix - {best_model_name}')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
print("âœ… Saved: confusion_matrix.png")

# 3. Feature Importance (if available)
if hasattr(best_model, 'feature_importances_'):
    importances = best_model.feature_importances_
    indices = np.argsort(importances)[::-1]
    
    plt.figure(figsize=(10, 6))
    plt.bar(range(len(importances)), importances[indices])
    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')
    plt.title(f'Feature Importances - {best_model_name}')
    plt.ylabel('Importance')
    plt.tight_layout()
    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
    print("âœ… Saved: feature_importance.png")

# ============================================================
# BÆ¯á»šC 9: TEST PREDICTION
# ============================================================
print("\nğŸ§ª BÆ¯á»šC 9: Testing prediction with sample data...")

# Sample input (khá»›p vá»›i form trong HealthManagement)
sample = {
    'Age': 55,
    'Sex': 1,  # Male
    'ChestPainType': 2,
    'RestingBP': 140,
    'Cholesterol': 250,
    'FastingBS': 1,
    'MaxHR': 150,
    'ExerciseAngina': 0
}

print(f"\nğŸ“ Sample Input:")
for key, value in sample.items():
    print(f"   {key}: {value}")

# Convert to DataFrame with correct feature order
sample_df = pd.DataFrame([sample])

# Äáº£m báº£o columns khá»›p vá»›i training data
for col in feature_names:
    if col not in sample_df.columns:
        sample_df[col] = 0  # Default value

sample_df = sample_df[feature_names]

# Predict
sample_scaled = scaler.transform(sample_df)
prediction = best_model.predict(sample_scaled)[0]
probability = best_model.predict_proba(sample_scaled)[0] if hasattr(best_model, 'predict_proba') else None

print(f"\nğŸ¯ Prediction Result:")
print(f"   Class: {prediction} ({'Disease' if prediction == 1 else 'No Disease'})")
if probability is not None:
    print(f"   Probability: {probability[1]*100:.2f}% risk")
    if probability[1] >= 0.7:
        print(f"   Risk Level: HIGH âš ï¸")
    elif probability[1] >= 0.4:
        print(f"   Risk Level: MEDIUM âš¡")
    else:
        print(f"   Risk Level: LOW âœ…")

# ============================================================
# HOÃ€N THÃ€NH
# ============================================================
print("\n"+"="*70)
print("âœ… TRAINING COMPLETED SUCCESSFULLY!")
print("="*70)
print("\nğŸ“ Generated Files:")
print("   1. heart_disease_model.pkl      - Trained model")
print("   2. heart_disease_scaler.pkl     - Feature scaler")
print("   3. heart_disease_features.pkl   - Feature names")
print("   4. model_comparison.png         - Accuracy comparison chart")
print("   5. confusion_matrix.png         - Confusion matrix")
if hasattr(best_model, 'feature_importances_'):
    print("   6. feature_importance.png       - Feature importance chart")

print("\nğŸš€ Next Steps:")
print("   1. Táº¡o Flask API (xem file flask_api.py)")
print("   2. Cháº¡y Flask server")
print("   3. Update AIService.cs trong HealthManagement Ä‘á»ƒ gá»i API")
print("   4. Test prediction tá»« web application")

print("\n"+"="*70)
